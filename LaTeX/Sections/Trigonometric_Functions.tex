%SEC%
\section{Trigonometric Functions}

This section will focus on trigonometric functions, which are commonly used cyclic functions. These functions have been studied for hundreds of years, and can be challenging to calculate. We will discuss several methods of calculating them below before comparing methods.

\TODO{Extend and Eloquate introduction}

%SUB%
\subsection{Calculating \pi}
\label{SUB_"Calculating pi"}

Several of the methods in this section require that we already know the value of \(\pi\), for example when we are applying several trig identities. Here we will briefly discuss several methods for calculating the value of \(\pi\), so that we may use this value in later subsections.

\TODO{Fill out with content methods}

%SUB%
\subsection{Geometric Method}
\label{SUB_"Trig Geometric Method"}

\theoremstyle{plain}
\newtheorem{Geo Trig Prop 1}{Proposition}[subsection]
\newtheorem{Geo Trig Prop 2}[Geo Trig Prop 1]{Proposition}
\newtheorem{Geo Trig Prop 3}[Geo Trig Prop 1]{Proposition}

The first method I will be discussing is a method based on geometric properties that are derived on a circle, and we will start by considering values of \(\cos\) in the range \([0, \frac{\pi}{2}]\). To do this we will consider the following figure of the unit circle:

%FIG%
\begin{figure}[!ht]
	\label{FIG_"Geometric Trig 1"}
	\caption{Diagram showing angles to be dealt with}
	\centering
	\includegraphics[width=0.5\textwidth]{"./Diagrams/Geometric Trig Diagram 1"}
\end{figure}

Here theta will be given in radians, and we can note that the labelled arc has length \(\theta\) due the formula for the circumference of a circle. By using the following derivation we can find a formula for \(\theta\) in terms of \(s\):

\begin{displaymath}
\begin{align*}
	s^2 &= \sin^2\theta + (1 - \cos\theta)^2\\
	    &= (\sin^2\theta + \cos^2\theta) + 1 - 2\cos\theta\\
		&= 2 - 2 \cos\theta 
			&\mathrm{By using } \sin^2\theta + \cos^2\theta = 1\\
	\cos\theta &= 1 - \frac{s^2}{2}
\end{align*}
\end{displaymath}

We will now consider a second diagram which will allow us to calculate an approximate value of \(s\).

%FIG%
\begin{figure}[!ht]
	\label{FIG_"Geometric Trig 2"}
	\caption{Diagram detailing how to calculate \(s\)}
	\centering
	\includegraphics[width=0.5\textwidth]{"./Diagrams/Geometric Trig Diagram 2"}
\end{figure}

We will first note that by an elementary geometry result we can know that the angle \(ABC\) is a right-angle; also we can consider that \(h\) is an approximation of \(\tfrac{\theta}{2}\), which will become relevant later. Now because \(AC\) is a diameter of our circle then it's length is 2 and thus, by utilising Pythagarus' Theorem, we get that the length of \(AB\) is \(\sqrt{AC^2 - BC^2} = \sqrt{4 - h^2}\).\\

From here we consider the area of triangle \(ABC\), which can be calculated as \(\frac{1}{2}\cdot h\cdot\sqrt{4-h^2}\) and as \(\frac{1}{2}\cdot2\cdot\frac{s}{2}\); by equating these two, squaring both sides and re-arranging we get that \(s^2 = h^2(4 - h^2)\). Now we have the basis for a method that will allow us to calculate \(\cos\theta\).\\

To complete our method we will consider introducing a new line that is to \(h\) what \(h\) is to \(s\) as shown in the diagram below:

%FIG%
\begin{figure}[!ht]
	\label{FIG_"Geometric Trig 3"}
	\caption{Detailing the recursive steps}
	\centering
	\includegraphics[width=0.5\textwidth]{"./Diagrams/Geometric Trig Diagram 3"}
\end{figure}

It is easy to see that if we repeat the steps above we get that \(h^2 = \hat{h}^2(4 - \hat{h}^2)\), and it also follows that \(\hat{h} \approx \frac{\theta}{4}\). Using this we can take an initial guess of \(h_0 := \frac{\theta}{2^k}\), for some \(k \in \N\), and then calculate \(h_{n+1}^2 = h_n^2(4 - h_n^2)\) where \(n \in [0, k] \cap \Z\); finally we calculate \(\cos\theta = 1 - \frac{h_k^2}{2}\), giving the following algorithm:
  
%PCD%
\begin{lstlisting}[numbers=left,frame=single,mathescape,caption={Geometric calculation of \(\cos\)},label={PCD_"Geometric Cos"}]
  geometric_cos($\theta \in [0, \frac{\pi}{2}], k \in \N$)
      $h_0 := \tfrac{\theta}{2^k}$
      $n := 0$
      while $n < K$:
          $h_{n+1}^2 := h_n^2\cdot(4 - h_n^2)$
          $n \mapsto n + 1$
      return $1 - \tfrac{h_k^2}{2}$
\end{lstlisting}\\

Now we can use the above pseudocode to calculate any trigonometric function value by using various trigonometric identities. First we  suppose \(\theta \in \R\), then we can repeatedly apply the identity \(\cos\theta = \cos(\theta \pm 2\pi)\) to either add or subtrack \(2\pi\) until we have a value \(\theta' \in [0, 2pi)\). Once we have this value we can utilise the following assignment to calculate \(\cos\theta\):

\begin{displaymath}
	\cos\theta = \left\{ \begin{array}{lcl}
			\cos\theta' & : & \theta' \in [0, \frac{\pi}{2}]\\
			-\cos(\pi - \theta') & : & \theta' \in [\frac{\pi}{2}, \pi]\\
			-\cos(\theta' - \pi) & : & \theta' \in [\pi, \frac{3\pi}{2}]\\
			\cos(2\pi - \theta') & : & \theta' \in [\frac{3\pi}{2}, 2\pi)
		\end{array}\right.
\end{displaymath}

Using Algorithm \ref{PCD_"Geometric Cos"} we can also easily calculate both \(\sin\theta\) and \(\tan\theta\), by further use of trigonometric identities. In particular we note that \(\sin\theta = \cos(\theta - \frac{\pi}{2}\) and \(\tan\theta = \frac{\sin\theta}{\cos\theta}\). Hence we can now calculate the trigonometric function value of any angle.\\

We now wish to analyse the error of our approximation for \(\cos\), as the other methods have errors that are derivative of the error for approximating \(\cos\). Now Figure \ref{FIG_"Geometric Trig 4"} shows an arc of a circle which creates chord \(x\), with this we will be able to calculate the exact length of the chord and thus work on the error of our approximations.\\

%FIG%
\begin{figure}[!ht]
	\caption{Diagram to find actual arc approximation}
	\label{FIG_"Geometric Trig 4"}
	\centering
	\includegraphics[width=0.5\textwidth]{"./Diagrams/Geometric Trig Diagram 4"}
\end{figure}

To start we will note that \(\phi = \frac{\pi - \theta}{2} = \frac{\pi}{2} - \frac{\theta}{2}\), and then by using the Sine Law we get 
\[\frac{x}{\sin\theta} = \frac{1}{\sin\phi} \implies x = \frac{\sin\theta}{\sin\phi}\]

Now we can recall the double angle formula for \(\sin\), which gives \(\sin\theta = 2\sin\frac{\theta}{2}\cos\frac{\theta}{2}\), and also \(\sin\phi = \cos\frac{\theta}{2}\). This allows us to see that
\[x = \frac{2\sin\frac{\theta}{2}\cos\frac{\theta}{2}}{\cos\frac{\theta}{2}} = 2\sin\tfrac{\theta}{2}\]

Therefore we see that \(h_n\) is approximating the chord length associated with angle \(\theta2^{n-k}\), and thus \(\epsilon_n = |h_n - 2\sin(\theta2^{n-k-1})|\). Now as \(h_0 =\theta2^{-k} \approx 2\sin(\theta2^{-k-1})\) then if follows that \(\exists \phi\) such that \(h_0 = 2\sin(\phi2{-k-1})\), from this we can see that \(\phi = 2^{k+1}\sin^{-1}(\theta2^{-k-1})\). We will uses these facts to prove a couple of propositions.

%THM%
\begin{Geo Trig Prop 1}
\label{THM_"Geo Trig Prop 1"}
\(h_n = 2\sin(\phi2^{n-k-1}) \forall n \in [0, k] \cap \Z\) where \(\phi := 2^{k+1}\sin^{-1}(\theta2^{-k-1})\).
\end{Geo Trig Prop 1}
\begin{proof}
Proceed by induction on \(n \in [0, k]\cap\Z\).\\
\begin{description}
\item [\textrm{H\((n)\):}] \(h_n = 2\sin(\phi2^{n-k-1})\)
\item [\textrm{H\((0)\):}] 
	\begin{displaymath}
		\begin{align*}
			2\sin(\phi2^{-k-1}) &= 2\sin(\sin^{-1}(\phi2^{-k-1}))\\
								&= \theta2^{-k}\\
								&= h_0 & \textrm{by definition of } h_0
		\end{align*}
	\end{displaymath}
\item [\textrm{H\((n)\) \(\implies\) H\((n+1)\):}]
	\begin{displaymath}
		\begin{align*}
			h_{n+1} &= h_n\sqrt{4-h_n^2}\\
					&= 2\sin(\phi2^{n-k-1})\sqrt{4-4\sin^2(\phi2^{n-k-1})}
						&\textrm{by H\((n)\)}\\
					&= 4\sin(\phi2^{n-k-1})\cos(\phi2^{n-k-1})\\
					&= 2\sin(\phi2^{n-k})
						&\textrm{by the use of double angle formulas}
		\end{align*}
	\end{displaymath}
\end{description}
\end{proof}

%THM%
\begin{Geo Trig Prop 2}
\label{THM_"Geo Trig Prop 2"}
\(h_n > 2\sin(\theta2^{n-k-1}) \forall n \in [0,k] \cap \Z\)
\end{Geo Trig Prop 2}
\begin{proof}
We start by considering the expansion of the exact value of \(h_n\).
\begin{displaymath}
	\begin{align*}
		h_n &= 2\sin(\phi2^{n-k-1})\\
			&= 2\sin(2^{n-k-1}(2^{k+1}\sin^{-1}(\theta2^{-k-1})))\\
			&= 2\sin(2^n\sin^{-1}(\theta2^{-k-1}))\\
			&= 2\sin(\theta2^{n-k-1} + \tfrac{1}{6}\theta^32^{n-3k -3} 
				+ \bigO(2^{-5k}))
				& \textrm{Detailed in section \ref{#REF#}}
	\end{align*}
\end{displaymath}

Now as we know that \(n \le k\), then it follows that \(\theta2^{n-k-1} \le \tfrac{1}{2}\theta\).\\

Also as \(\theta \le \tfrac{\pi}{2}\) we know that \(\theta2^{n-k-1} \le \tfrac{\pi}{4}\).\\

We can also show that \(\tfrac{1}{6}\theta^32^{n-3k-3} + \bigO(2^{-5k}) \le \tfrac{\pi}{4}\), though the proof is ommited here for brevity; therefore we see that \(\phi2^{n-k-1} \le \tfrac{\pi}{2}\), and obviously that \(\phi2^{n-k-1} > \theta2^{n-k-1}\).\\

Hence, as \(\sin\) is an increasing function in the range \([0, \tfrac{\pi}{2}]\), we conclude that \[h_n = 2\sin(\phi2^{n-k-1}) > 2\sin(\theta2^{n-k-1})\].
\end{proof}

With these two propositions we can now consider the error of our approximation of \(\cos\). First we will prove the following proposition regarding the error of the approximation of \(s\):

%THM%
\begin{Geo Trig Prop 3}
\label{THM_"Geo Trig Prop 3"}
If \(\epsilon_n := |h_n - 2\sin(\theta2^{n-k-1})| \forall n \in [0,k] \cap \Z\), then \(\epsilon_k < 2^k\epsilon_0)\).
\end{Geo Trig Prop 3}
\begin{proof}
\(\epsilon_n = h_n - 2\sin(\theta2^{n-k-1})\) as \(h_n > 2\sin(\theta2^{n-k-1})\) by Proposition \ref{THM_"Geo Trig Prop 2"}.\\

Now we see that:
\begin{displaymath}
\begin{align*}
	\epsilon_{n+1} &= h_{n+1} - 2\sin(\theta2^{n-k})\\
		&= h_n\sqrt{4-h_n^2} 
			- 4\sin(\theta2^{n-k-1})\cos(\theta2^{n-k-1})\\
\end{align*}
\end{displaymath}

If we consider the equation \(\alpha\beta - \gamma\delta = (\alpha - \gamma) + \alpha(\beta - 1) - \gamma(\delta - 1)\) and apply it to our current formula we get:

\begin{displaymath}
\begin{align*}
	\epsilon_{n+1} &= (h_n - 2\sin(\theta2^{n-k-1})) 
						+ h_n(\sqrt{4 - h_n^2} - 1)
						- 2\sin(\theta2^{n-k-1})(2\cos(\theta2^{n-k-1}) - 1)\\
		&= \epsilon_n + h_n(\sqrt{4 - h_n^2} - 1)
			-2\sin(\theta2^{n-k-1})(2\cos(\theta2^{n-k-1}) - 1)\\
		&= 2\epsilon_n + h_n(\sqrt{4 - h_n^2} - 2)
			-2\sin(\theta2^{n-k-1})(2\cos(\theta2^{n-k-1}) - 2)\\
		&= 2\epsilon_n + h_n(\sqrt{4 - h_n^2} - 2)
			+2\sin(\theta2^{n-k-1})(2 - 2\cos(\theta2^{n-k-1}))\\
		&< 2\epsilon_n + h_n(\sqrt{4 - h_n^2} - 2\cos(\theta2^{n-k-1}))\\
		&< 2\epsilon_n + h_n(\sqrt{4 - 4\sin^2(\theta2^{n-k-1})}
			- 2\cos(\theta2^{n-k-1}))\\
		&= 2\epsilon_n + h_n(2\cos(\theta2^{n-k-1}) 
			- 2\cos(\theta2^{n-k-1}))\\
		&= 2\epsilon_n
\end{align*}
\end{displaymath}

The inequalities in the above derivation arrise from the fact that \(h_n > 2\sin(\theta2^{n-k-1})\) by Proposition \ref{THM_"Geo Trig Prop 2"}.\\

Hence as we now know that \(\epsilon_{n+1} < 2\epsilon_n\), we then see that \(\epsilon_n < 2^n\epsilon_0\). Therefore we prove our statement that
\[\epsilon_k < 2^k\epsilon_0\]
\end{proof}

Obviously \(\epsilon_k = |h_k - s|\), and we can now use this to find the error of our final answer. First we will start by letting \(\mathcal{C} := 1-\tfrac{1}{2}h_k^2\) and note that analytically \(cos\theta = 1 - \tfrac{1}{2}s^2\). Therefore we will now consider \(\epsilon_{\mathcal{C}} = |\mathcal{C} - \cos(\theta)|\):

\begin{displaymath}
\begin{align*}
	\epsilon_{\mathcal{C}} &= | 1 - \frac{h_k^2}{2} - 1 + \frac{s^2}{2}|\\
		&=\frac{1}{2}|h_k^2 - s^2|\\
		&=\frac{1}{2}|h_kh_k 
			- 2\sin(\frac{\theta}{2})2\sin(\frac{\theta}{2})|\\
		&=\frac{1}{2}(h_kh_k 
			- 2\sin(\frac{\theta}{2})2\sin(\frac{\theta}{2})
			&\textrm{as \(2\sin(\frac{\theta}{2}) < h_k\)}\\
		&=\frac{1}{2}(2\epsilon_k + h_k(h_k-2) - 2\sin(\frac{\theta}{2})
			(2\sin(\frac{\theta}{2}) - 2)\\
		&<\frac{1}{2}(2\epsilon_k + h_k(h_k - 2\sin(\frac{\theta}{2})))\\
			&=\frac{1}{2}(2+h_k)\epsilon_k\\
		&=\frac{1}{2}(2 + 2\sin(\frac{\phi}{2}))\epsilon_k\\
		&=(1 + \sin(\frac{\phi}{2}))\epsilon_k\\
		&\le2\epsilon_k
\end{align*}
\end{displaymath}

As \(\epsilon_{\mathcal{C}} \le 2\epsilon_k\), then by Proposition \ref{THM_"Geo Trig Prop 3"} we see that \(\epsilon_{\mathcal{C}} < 2^{k+1}\epsilon_0\). Now to consider \(\epsilon_0\) we first observe that \(\epsilon_0 =\theta2^{-k} - 2\sin{\theta2^{-k-1}\), and therefore we can conclude that:
\[\epsilon_{\mathcal{C}} < 2\theta - 2^{k+2}\sin(\theta2^{-k-1})\]

If we then wish to calculate \(\cos\theta\) accurate to \(N\) decimal places then we are looking to find \(k \in \N\) such that
\[2\theta - 2^{k+2}\sin(\theta2^{-k-1}) < 10^{-N} \implies 2^{k+2}\sin(\theta2^{-k-1}) > 2\theta - 10^{-N}\]

For an example of the above in action we will be taking \(\theta = 0.5\). The table below shows the minimum \(k \in \N\) to guarantee \(N\) digits of accuracy in the result:

%TBL%
\begin{center}
\begin{tabular}{|p{3cm}|p{3cm}|}
	\hline
	\(N\) & \(k\)\\
	\hline
	5 & 6\\\hline
	10 & 14\\\hline
	50 & 80\\\hline
	100 & 163\\\hline
	1000 & 1658\\\hline
\end{tabular}
\end{center}

As can be seen the value of \(k\) required to acheive \(N\) digits of accuracy increases roughly linearly when \(\theta = 0.5\). Testing for other values of \(\theta\) reveals them to have similar required values for \(k\), at least within the same order of each other.\\

Another consideration for Algorithm \ref{PCD_"Geometric Cos"} is that we could "run it in reverse" to attain an algorithm for the inverse cosine function. To start take line 7 which is \(\mathcal{C} = 1 - \frac{1}{2}h_k^2\), which can be re-arranged to give \(h_k^2 = 2 - 2\mathcal{C}\), where we know \(\mathcal{C}\) as our initial value.\\

Line 5 is a little more difficult, but by re-arranging we see that \(h_n^4 - 4h_n^2 + h_{n+1}^2 = 0\), which can be solved via the quadratic formula to give \(h_n^2 = 2 \pm \sqrt{4 - h_{n+1}^2}\). Now we can make the observation that if \(x \in \Rpz\), then \(\cos^{-1}(-x) = \pi - \cos^{-1}(x)\) and so we can restric our algorithm to only consider \(x \in [0,1]\). With this we know that \(\theta \in [0,\frac{\pi}{2}]\), and thus \(h_k \le \sqrt{2}\). Therefore as \(h_{n+1} > h_n \forall n \in [0,k-1]\cap\Z\) we see that \(h_n^2 \le 2 \forall n \in [0,k]\cap\Z\). This allows us to ascertain that to reverse Line 5 we perform \(h_n^2 = 2 - \sqrt{4 - h_{n+1}^2}\).\\

Finally line 2 is reversed by returning the value \(2^kh_0\); therefore we get the following algorithm for \(\cos^{-1}(x)\) where \(x \in [0,1]\):

%PCD%
\begin{lstlisting}[numbers=left,frame=single,mathescape,caption={Geometric calculation of \(\cos^{-1}\)},label={PCD_"Geometric aCos"}]
  geometric_aCos($x \in [0,1], k \in \N$)
      $h_k := 2 - 2x$
      $n := k-1$
      while $n \ge 0$:
          $h_n^2 := 2 - \sqrt{4 - h_{n+1}^2}$
          $n \mapsto n - 1$
      return $2^kh_0$
\end{lstlisting}\\

Similar to the regular trigonometric functions we can use trigonometric identities to calculate the inverse trigonometric functions from \(\cos^{-1}\). To start we recall that \(\cos^{-1}(-x) = -\cos(x)\) where \(x \in [0,1]\), then we can use the identities that \(\sin^{-1}(x) = \frac{\pi}{2} - \cos^{-1}(x)\) and \(\tan^{-1}(x) = \sin^{-1}(\frac{x}{\sqrt{x^2 + 1}})\).\\

If we suppose that all operations in the method are accurately computed then Algorithm \ref{PCD_"Geometric aCos"} is a computation with high accuracy. This is because there is no initial guess, such as in Algorithm \ref{PCD_"Geometric Cos"}, and so the only introduction of error is assuming that \(2^kh_0 \approx \theta\). However as we discuss in detail in Section \ref{#SEC#}, calculating square roots is not a simple task and thus will introduce error to the method in general; therefore the accuracy of the method is roughly as accurate as our method of calculating square roots.

%SUB%
\subsection{Taylor Series}
\label{SUB_"Taylor Series Trig"}

If we consider our definition of a McClaurin Series from Section \ref{#SUB#}, we can use this to approximate our Trigonometric Functions. Consider first \(\cos\theta\), for which we know that \(\frac{d}{d\theta}\cos\theta = - \sin\theta\); it then follows that \(\frac{d^2}{d\theta^2}\cos\theta = -\cos\theta\), \(\frac{d^3}{d\theta^3} \cos\theta = \sin\theta\) and \(\frac{d^4}{d\theta^4} \cos\theta = \cos\theta\).\\

If we let \(f(x) = \cos x\) and use the known values \(\cos(0) = 1\) and \(\sin(0) = 0\), then we see that:

\begin{displaymath}
	f^{(n)}(0) = \left\{
		\begin{array}{lcl}
			1 &:& 4 \mid n\\
			0 &:& 4 \mid n-1\\
			-1 &:& 4 \mid n-2\\
			0 &:& 4 \mid n-3
		\end{array}\right.
\end{displaymath}

By simplifying this by ommitting the \(0\) coefficient terms we get the following series:

%EQN%
\begin{equation}
\label{EQN_"Cos Series Formula"}
\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}x^{2n} = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots
\end{equation}

By using similar working we can get that the series associated with \(\sin\(x)\):

%EQN%
\begin{equation}
\label{EQN_"Sin Series Formula"}
\sum_{n=0}^\infty \frac{(-1)^n}{(2n+1)!}x^{2n+1} = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots
\end{equation}

Before we go any further we need to consider when Equations \ref{EQN_"Cos Series Formula"} and \ref{EQN_"Sin Series Formula"} converge to their respective functions. To do this we will use the ratio test for series as defined in \ref{#SEC#}, using Equation \ref{EQN_"Cos Series Formula"} we see that

\begin{displaymath}
	\begin{align*}
		L_{\mathcal{C}} &= \lim_{n \to \infty} \left| 
			\frac{a_{n+1}}{a_n} \right|\\
		&= \lim_{n \to \infty} \left| 
			\frac{\frac{(-1)^{n+1}}{(2n+2)!}x^{2n+2}}
				{\frac{(-1)^n}{(2n)!}x^{2n}} \right|\\
		&=\frac{(2n)!}{(2n+2)!}|x|^2\\
		&=\frac{1}{(2n+2)(2n+1)}|x|^2
	\end{align*}
\end{displaymath}

Now it is easy to see that, \(L_{\mathcal{C}} = 0\) for all values of \(x\) as the fractional component decreases as \(n\) increases and \(|x|^2\) is a constant. Therefore we can conclude that Equation \ref{EQN_"Cos Series Formula"} converges to \(\cos(x)\) for all values of \(x\). We can use a very similar deduction to show that Equation \ref{EQN_"Sin Series Formula"} converges to \(\sin(x)\) for all values of \(x\).\\

The above means that \(\cos\) and \(\sin\) can be approximated using Taylor Polynomials, in particular for a given \(N \in \N\):
\begin{displaymath}
\begin{array}{rcl}
	\cos x \approx \sum_{n=0}^N \frac{(-1)^n}{(2n)!}x^{2n}
	& \textrm{and}
	&\sin x\approx \sum_{n=0}^N \frac{(-1)^n}{(2n+1)!}x^{2n+1}
\end{array}
\end{displaymath}

This allows us to create the following two methods for computing \(\cos x\) and \(\sin x\):

%PCD%
\begin{lstlisting}[numbers=left,frame=single,mathescape,caption={Taylor computation of \(\cos\) and \(\sin\)},label={PCD_"Taylor Cos/Sin"}]
  taylor_cos($x \in \R, N \in \N$)
      $\mathcal{C} := 0$
      $n := 0$
      while $n < N$:
          $\mathcal{C} \mapsto \mathcal{C} + (-1)^n\cdot\tfrac{1}{(2n)!}x^{2n}$
          $n \mapsto n+1$
      return $\mathcal{C}$
  
  taylor_sin($x \in \R, N \in \N$)
      $\mathcal{S} := 0$
      $n := 0$
      while $n < N$:
          $\mathcal{S} \mapsto \mathcal{S} + (-1)^n\cdot\tfrac{1}{(2n+1)!}x^{2n+1}$
          $n \mapsto n+1$
      return $\mathcal{S}$
\end{lstlisting}

As these two methods are obviously very similar and the fact that \(\sin(x) = \cos(x - \frac{\pi}{2})\), we will continue by examining only the taylor method for approximating \(\cos\). We will assume that any calculations for \(\sin\) are transformed into a problem of finding a \(\cos\) value.\\

It should be noted that this \(\cos\) algorithnm is particularly inefficient to calculate on a computer implementation; this is primarily due to the way in which the update of \(\mathcal{C}\) is calculated each loop.\\

In each loop we are calculating \(x^{2n}\), which has a naieve complexity of \(\bigO(2n)\). However what we are actually calculating \(x^{2(n-1)}\cdot x^2\) and thus if we store the values of \(x^{2(n-1)}\) and \(x^2\), the complexity of this step drops to \(\bigO(1)\). Similarly we are also calculating \(\tfrac{1}{(2n)!}\) in each loop which, by the same logic, is \(\tfrac{1}{2(n-1)!} \cdot \tfrac{1}{(2n)(2n-1)}\), and we can use the same storage and update method as for \(x^{2n}\).\\

As another step towards optimizing the algorithm we can start with an initial value of \(\mathcal{C} = 1\), and then perform two updates of \(\mathcal{C}\) each loop until we reach or surpass \(N\). This saves calculating \((-1)^n\) each loop, by explicitly performing two different calculations. Implementing all of the above gives us the following two updated methods:

%PCD%
\begin{lstlisting}[numbers=left,frame=single,mathescape,caption={Taylor computation of \(\cos\) optimised},label={PCD_"Taylor Cos opt"}]
  taylor_cos($x \in \R, N \in \N$)
      $\mathcal{C} := 1$
      $x_2 := x^2$
      $a := 1$
      $b := 1$
      $n := 1$
      while $n < N$:
          $a \mapsto a \cdot \tfrac{1}{(2n-1)(2n)}$
          $b \mapsto b \cdot x_2$
          $\mathcal{C} \mapsto \mathcal{C} - a\cdot b$
          $a \mapsto a \cdot \tfrac{1}{(2n+1)(2n+2)}$
          $b \mapsto b \cdot x_2$
          $\mathcal{C} \mapsto \mathcal{C} + a\cdot b$
          $n \mapsto n+2$
      return $\mathcal{C}$
\end{lstlisting}

As the next term of the polynomial is known definitively then we can see that it is very easy to calculate the error of our approximation. We see that 
\begin{displaymath}
\begin{align*}
	\epsilon_N &= |\cos(x) - \mathrm{taylor\_cos(x,N)}|\\
		&= \bigO(|x|^{N'+1}) &\textrm{where } N' \textrm{ is the smallest}\\
		&&\textrm{odd integer such that } N'\ge N\\
		&\le \frac{1}{(2(N'+1))!} |x|^{N'+1}\\
		&\le \frac{1}{(2(N+1))!} |x|^{N+1}
\end{align*}
\end{displaymath}

If we place bounds on the value of \(\cos\) calculated as in Section \ref{SUB_"Trig Geometric Method"}, then we know that \(|x| \le \frac{\pi}{2}\), and thus we get the following bound for the error of our approximation:

\[\epsilon_N \le \frac{\pi^{N' + 1}}{2^{N'+1}(2(N'+1))!}\]

Thus if we find \(N \in \N\) such that \(\frac{\pi^{N}+1}{2^{N+1}(2(N+1)!)} < \tau \in \R+\) then we know that \(\epsilon_N < \tau\). If we consider \(\tau = 10^k\), then we can find \(N \in \N\) such that our approximation is accurate to \(k\) decimal places. Below is a table which details some values of \(k\) and the corresponding minimum \(N\) to guarantee \(k\) decimal places of accuracy:

%TBL%
\begin{center}
\begin{tabular}{|p{3cm}|p{3cm}|}
	\hline
	\(k\) & \(N\)\\
	\hline
	5 & 4\\\hline
	10 & 7\\\hline
	50 & 21\\\hline
	100 & 36\\\hline
	1000 & 233\\\hline
\end{tabular}
\end{center}

Now for \(\tan x\) we can either calculate both \(\sin x\) and \(\cos x\) using \mathrm{taylor\_cos(x,N)} and divide the resulting value, or we can calculate \(\tan x\) directly using a Taylor expansion.\\

In calculating the McClaurin series for \(\tan x\) we start by letting \(\tan x = \sum_{n=0}^\infty a_nx^n\), and then noting that as \(\tan x\) is an odd series then it's McClaurin series only contains non-zero coefficients for odd powers of \(x\); therefore we get that \(\tan x = \sum_{n=0}^\infty a_{2n+1}x^{2n+1} = a_1x + a_3x^3 + a_5x^5 + \cdots\).\\

Next we consider that \(\frac{d}{dx} \tan x = 1 + \tan^2 x\), and knowing the McClaurin series form of \(\tan x\) we get the following:

\begin{displaymath}
\begin{align*}
	\sum_{n=0}^\infty (2n+1)a_{2n+1}x^{2n} &= 1 + 
		(\sum_{n=0}^\infty a_{2n+1}x^{2n+1})^2\\
	&= 1 + a_1^2x^2 + (2a_1a_3)x^4 + (2a_1a_5 + a_3^2)x^6 + \cdots
\end{align*}
\end{displaymath}

Considering the co-efficients of powers on the right hand side of the above equation we see that \(2a_1a_3 = a_1a_3 + a_3_a_1 = a_1a_{4-1} + a_3a_{4-3}\) and \(2a_1a_5 + a_3^2 = a_1a_5 + a_3a_3 + a_5a_1 = a_1a_{6-1} + a_3a_{6-3} +a_5a_{6-5}\). This indicates that our general form for the co-efficient of \(2n\) on the right hand side is \(\sum_{k=1}^n a_{2k-1}a_{2n - 2k + 1}\), and thus returning to our equation we get

\[a_1 + \sum_{n=1}^\infty (2n+1)a_{2n+1}x^{2n} = 1 + \sum_{n=1}^\infty(\sum_{k=1}^n a_{2k-1}a_{2n-2k+1})x^{2n}\]

Using this we conclude that \(a_1 = 1\) and \(a_{2n+1} = \frac{1}{2n+1}\sum_{k=1}^n a_{2k-1}a_{2n-2k+1} \forall n \in \N\). We can note immediately that the calculation of any previous co-efficients will provide no help in calculating later co-efficients and so the entire sum must be calculated each loop, while also storing each co-efficient already calcualted.\\

This means that the complexity to calculate co-efficient \(a_{2n+1}\) is \(\bigO(n)\) and will be the \(n^\text{th}\) such calculation, making the complexity of calculating \(n\) co-efficients to be \(\bigO(n^2)\). Comparing this to the \mathrm{taylor\_cos} method we see that to calculate up to \(n\) co-efficients of both \(\cos\) and \(\sin\) has complexity \(\bigO(n)\). Therfore it is more efficient to calculate \(\tan\) by calculating both \(\cos\) and \(\sin\) using Algorithm \ref{PCD_"Taylor Cos Opt"}, and performing division than directly using Taylor Polynomial approximation.\\

We would also like to be able to calculate the inverse trigonometric functions using this method, which means we need to find our McClaurin series of the inverse trigonometric functions. The simplest of these is \(\tan^{-1}\), where we start by recalling that \(\frac{d}{dx} \tan^{-1} x = \frac{1}{1+x^2}\) and then by intergrating both sides we get:

\begin{displaymath}
\begin{align*}
	\tan^{-1} x &= \int \frac{1}{1+x^2} dx\\
		&= \int (1 - (-x^2))^-1 dx\\
		&= \int \sum_{n=0}^\infty (-x^2)^n dx &\textrm{by Equation \ref{#EQN#}}\\
		&= \int \sum_{n=0}^\infty (-1)^nx^{2n} dx\\
		&= c + \sum_{n=0}^\infty \frac{(-1)^n}{2n+1}x^{2n+1}
\end{align*}
\end{displaymath}

As \(\tan^{-1} (0) = 0\) then we see that \(c = 0\) and thus gives us the following formula for \(\tan^{-1}\):

\[\tan^{-1} x = \sum_{n=0}^\infty \frac{(-1)^n}{2n+1}x^{2n+1}\]

Now due to the restrictions from Equation \ref{#EQN#} the above is only valid for \(x \in [-1, 1]\), but we know that the domain of \(\tan^{-1}\) is \(x \in \R\). To fix this we will first recognise that \(\tan^{-1}(-x) = -\tan^{-1}(x)\), so we can restric our problem to \(x \in \Rpz\). Now if we take the double angle formula for \(\tan\):

\[\tan(\alpha + \beta) = \frac{\tan(\alpha) + \tan(\beta)}{1 - \tan(\alpha)\tan(\beta)}\]

By substituting \(\alpha = \tan^{-1}(x)\) and \(\beta = \tan^{-1}(x)\) into the above then we get

\[\tan^{-1}(x) + \tan^{-1}(y) = \tan^{-1}\left(\frac{x + y}{1 - xy}\right)\]

Using this, suppose we are looking for \(\tan^{-1}(z)\) where \(z \in (1, \infty)\) and let \(y = 1\), then \(\tan^{-1}(y) = \frac{\pi}{4}\). We can then re-arrange the equation \(z = \frac{x + 1}{1 - x}\) to get \(x = \frac{z - 1}{z + 1}\); finally as \(z > 1\), then \(0 < x < 1\). This allows us to calculate:

\[\tan^{-1}(z) = \frac{\pi}{4} + \tan^{-1}\left(\frac{z-1}{z+1}\right)\]

In the above the calculated value is in the range \([0, 1]\) and so it is valid to use a Taylor polynomial using our McClaurin series above. This gives the following method

%PCD%
\begin{lstlisting}[numbers=left,frame=single,mathescape,caption={Taylor Method for \(\tan^{-1}\)},label={PCD_"Taylor aTan"}]
  taylor_aTan($x \in [0,1], N \in \N$)
      $\mathcal{T} := 0$
      $x_2 := x^2$
      $y := x$
      $n := 0$
      while $n < N$:
          $\mathcal{T} \mapsto \mathcal{T} + \tfrac{1}{2n+1}y$
          $y\mapsto y\cdot x_2$
          $\mathcal{T} \mapsto \mathcal{T} - \tfrac{1}{2n+2}y$
          $y\mapsto y\cdot x_2$
          $n \mapsto n + 2$
      return $\mathcal{T}$
\end{lstlisting}

Similar to Algorithm \ref{PCD_"Taylor Cos Opt"} the error of Algorithm \ref{PCD_"Taylor aTan"} is easy to calculate. We see that 

\begin{displaymath}
\begin{align*}
	\epsilon_N &= |\tan^{-1}(x) - \mathrm{taylor\_aTan(x,N)}|\\
		&\le \frac{1}{2N + 3}|x|^{2N+3}\\
		&\le \frac{1}{2N + 3} &\textrm{as } x \le 1
\end{algin*}
\end{displaymath}

The next function we will consider is \(\sin^{-1}\), which starts it's derivation in much the same way as \(\tan^{-1}\). First we start by recalling that \(\frac{d}{dx} \sin^{-1}(x) = (1 - x^{2})^{-\frac{1}{2}}\), then by taking integrals of both sides we get the following derivation:

\begin{displaymath}
\begin{align*}
	\sin^{-1}(x) &= \int (1 - x^{2})^{-\frac{1}{2}} dx\\
		&= \int \sum_{n=0}^\infty \binom{-\frac{1}{2}}{n} (-x^2)^n\\
		&= c + \sum_{n=0}^\infty (-1)^n 
			\left(\prod_{k=1}^n \frac{-\tfrac{1}{2} - k + 1}{k}\right)
			\frac{x^{2n+1}}{2n+1}\\
		&= c + \sum_{n=0}^\infty \frac{(-1)^n}{n!(2n+1)} 
			\left(\prod_{k=1}^n \tfrac{1}{2} - k\right)
			x^{2n+1}\\
		&= c + \sum_{n=0}^\infty \frac{(-1)^{2n}}{n!(2n+1)}
			\left(\prod_{k=1}^n \frac{2k - 1}{2}\right)
			x^{2n+1}\\
		&= c + \sum_{n=0}^\infty \frac{1}{n!(2n+1)2^n}
			\left(\prod_{k=1}^n 2k - 1\right)
			x^{2n+1}\\
		&= c + \sum_{n=0}^\infty \frac{1}{n!(2n+1)2^n}
			(1\times3\times5\times\cdots\times(2n-1))
			x^{2n+1}\\
		&= c + \sum_{n=0}^\infty \frac{1}{n!(2n+1)2^n} \times
			\frac{1\times2\times3\times\cdots\times(2n)}{2\times4\times\cdots\times(2n)}x^{2n+1}\\
		&= c + \sum_{n=0}^\infty \frac{(2n)!}{(n!)^2(2n+1)4^n}x^{2n+1}
\end{align*}
\end{displaymath}

As \(\sin^{-1}(0) = 0\) then we see that \(c=0\). Because the above is valid for \(x \in (-1,1)\), and we know the values of \(\sin^{-1}(-1)\) and \(\sin^{-1}(1)\), then we can have the following method for evaluating \(\sin^{-1}\):

%PCD%
\begin{lstlisting}[numbers=left,frame=single,mathescape,caption={Taylor Method for \(\sin^{-1}\)},label={PCD_"Taylor aSin"}]
  taylor_aSin($x \in [-1,1], N \in \N$)
      if $x = 1$:
          return $\tfrac{\pi}{2}$
      if $x = -1$:
          return $-\tfrac{\pi}{2}$
      $\mathcal{S} := x$
      $x_2 := x^2$
      $y := x$
      $a := 1$
      $b := 1$
      $c := 1$
      $n := 1$
      while $n < N$:
          $a \mapsto 2n\cdot(2n-1)\cdot a$
          $b \mapsto n^2 \cdot b$
          $c \mapsto 4\cdot c$
          $y \mapsto x_2 \cdot y$
          $\mathcal{S} \mapsto \mathcal{S} + \tfrac{a}{b\cdot c \cdot(2n+1)}\cdot y$
          $n \mapsto n + 1$
      return $\mathcal{S}$
\end{lstlisting}

The error for this method is similar to the \(\tan^{-1}\) method, in that \(\epsilon_N \le \frac{(2(N+1))!}{((N+1)!)(2N+1)4^{N+1}}\). Finally we note that \(\cos^{-1}(x) = \tfrac{\pi}{2} - \sin^{-1}(x)\), and thus can be calculated from a value calculated with Algorithm \ref{PCD_"Taylor aSin"}.

%SUB%
\subsection{CORDIC}
CORDIC is an algorithm that stands for COrdinate Rotation DIgital Computer and can be used to calculate many functions, including Trigonometric Values. The CORDIC algorithm works by utilising Matrix Rotations of unit vectors. This algorithm is less accurate than some other methods but has the advantage of being able to be implemented for fixed point real numbers in efficient ways using only addition and bitshifting.\\

CORDIC works by taking an initial guess of
\begin{math}
	\mathbf{x}_0 = \left( 
		\begin{array}{c}
			1 \\
			0
		\end{array} \right)
\end{math}
which can be rotated through an anti-clockwise angle of $\gamma$ by the matrix
\begin{displaymath}
	\left( \begin{array}{cc}
		\cos{\gamma} & -\sin{\gamma} \\
		\sin{\gamma} &  \cos{\gamma}
	\end{array} \right)
	= \frac{1}{\sqrt{1 + \tan{\gamma}^2}} \left( \begin{array}{cc}
		1 & -\tan{\gamma} \\
		\tan{\gamma} & 1
	\end{array} \right)
\end{displaymath}

By taking taking smaller and smaller values of $\gamma$ we can create an iterative process to find $\mathbf{x}_n$ which converges, for a given $\beta \in (-\frac{\pi}{2}, \frac{\pi}{2})$, to
\begin{displaymath}
	\left( \begin{array}{c}
		\cos{\beta}\\
		\sin{\beta}
	\end{array} \right)
\end{displaymath}

