%SEC%
\section{General Definitions and Theorems}
\label{SEC_"General Definitions and Theorems"}

This section will list some general definitions and theorems which will be used throughout the document. This will not be an exhaustive or in depth view of such concepts but merely an overview to allow easier reading of the material going forwards.

%SUB%
\subsection{Methods}

In this document we will look at various functions, such as root functions, trigonometric functions, among others. Despite the variety of functions being analysed there are several methods that are useful for more than one function, or are worth analysing before their use.

%SUBSUB%
\subsubsection{Newton-Raphson Method}
\label{SUBSUB_"Newton-Raphson Method"}

\theoremstyle{definition}
\newtheorem{Newton Method}{Definition}[subsubsection]

The Newton-Raphson Method is named after Sir Isaac Newton and Joseph Raphson. It is a method that takes a continuously differentiable function \(f\) and it's derivative \(f'\), as well as an initial guess \(x_0\), to create successively more accurate solutions to \(x\) where \(f(x) = 0\).\\

The motivation of the method can be seen in figure \ref{FIG_"Newton-Raphson Demonstration"}, where we take an initial guess \(x_0\) of the root \(x^\ast\). The tangent to the curve above \(x_0\) is then found, and has the equation \(y = f'(x_0)(x-x_0) + f(x_0)\), by setting \(y = 0\) and solving for \(x\) we find \(x_1\). By repeating this process and starting from a good enough \(x_0\) we hope to find successively closer approximations to \(x^\ast\).

%FIG%
\begin{figure}[!ht]
	\label{FIG_"Newton-Raphson Demonstration"}
	\caption{Demonstration of Newton-Raphson Method}
	\centering
	\includegraphics[width=0.5\textwidth]{"./Diagrams/Newton-Raphson Diagram"}
\end{figure}

The specific definition of the Newton-Raphson method that I will be using in this document is below:

%DEF%
\begin{Newton Method}
\label{DEF_"Newton-Raphson Method"}
Given \(f \in \mathcal{C}(\R)\), \(f'\) being the derivative of \(f\), and \(x_0 \in \R\); then we define:
\begin{displaymath}
	x_{n+1} := x_n - \frac{f(x)}{f'(x)} \forall n \in \N
\end{displaymath}
\end{Newton Method}

The Newton Raphson method is not suitable for all problems and there are in fact many cases in which it behaves poorly. One such case is when \(f'(x_n) \approx 0\) as the value of \(x_{n+1}\) will be very close to \(x_n\) and thus \(f'(x_{n+1}) \approx 0\). Further bad choices of \(x_0\) can lead to the method diverging or entering cycles between two points indefinitely, however we will see that we do not need to be concerned with these issues for our uses of the method.

%SUBSUB%
\subsubsection{Taylor Series Expansion}
\label{SUBSUB_"Taylor Series"}
\theoremstyle{definition}
\newtheorem{Taylor Series}{Definition}[subsubsection]
\newtheorem{Taylor Polynomial}[Taylor Series]{Definition}

The Taylor Series formulation was created by Brook Taylor in 1715, based off of the work of Scottish mathematician James Gregory. The Taylor Series describes a method of representing any infinitely differentiable function as an infinite power series.

%DEF%
\begin{Taylor Series}
\label{DEF_"Taylor Series"}
Given \(f : \R \to \R\) which is infinitely differentiable on an open ball \(B\) centred at \(a \in \R\), we define the Taylor Series of \(f\) on \(B\) to be:
\[\sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n\]
\end{Taylor Series}

It was shown that on the open ball \(B\) from the above definition we have that \(f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n\), i.e. a function is equal to it's Taylor polynomial on the ball for which it is defined. We can then, use this fact to define a polynomial that will approximate our function \(f\) at \(x \in \mathcal{I} \subset \R\)

%DEF%
\begin{Taylor Polynomial}
\label{DEF_"Taylor Polynomial"}
Given \(f : \R \to \R\) which has a Taylor Series of
\( \sum_{n=0}^\infty c_n x^n \), we define the Taylor Polynomial of degree \(N \in \N\) to be
\[ p_N(x) := \sum_{n=0}^N c_n x^n = c_0 + c_1 x + c_2 x^2 + \dotsb + c_N x^N\]
\end{Taylor Polynomial}

A commonly used type of Taylor series is the McClaurin series which is a Taylor series in a ball around \(a = 0\). Thus a McClaurin series has the form:
\[\sum_{n=0}^N \frac{f^{(n)}(0)}{n!}x^n\]

Some examples of simple McClaurin Series are:
\begin{align*}
\frac{1}{1-x} &= \sum_{n=0}^\infty x^n &\forall x \in {({-1},1)}\\
(1 + x)^k	  &= \sum_{n=0}^\infty \binom{k}{n} x^n 
					&\forall x \in (-1,1), k \in \N
\end{align*}

%SUB%
\subsection{Errors}
\label{SUB_"Error Definitions"}
\theoremstyle{definition}
\newtheorem{Absolute Error}{Definition}[subsection]
\newtheorem{Iteration Error}[Absolute Error]{Definition}

The error of an approximation \(x_n\) for some \(x^\ast\) is a measure of how much \(x_n\) differs from \(x^\ast\). We will use the error of approximations to discuss the convergence of methods as well as describing their accuracy.\\

There are several ways of evaluating the error of an approximation which each have their own uses. The error measures that we will use in this document are detailed below:

%DEF%
\begin{Absolute Error}
\label{DEF_"Absolute Error"}
If we have a value \(v\) and it's approximation \(\tilde{v}\), then the absolute error is
\[ \epsilon := \left| v - \tilde{v} \right| \]
\end{Absolute Error}

The absolute error is useful in guaranteeing a certain level of accuracy that a given implementation of a method will give; for instance if \(epsilon < 10^{-3}\) then the approximation is accurate to at least 3 decimal places. Uses of absolute error in the document will use \(\epsilon\) as their absolute error variable.

As the absolute error of an approximation is hard or impossible to accurately calculate during program execution, we want a way to estimate it. Typically our computations will produce a sequence of approximations \(x_0, x_1, x_2, \ldots\), and thus we define the following:

%DEF%
\begin{Iteration Error}
\label{DEF_"Iteration Error"}
If we have the sequence \(\left(x_n\right)_{n \in \N}\), then the iteration error is defined as:
\[ \delta_n := \left|x_n - x_{n-1}\right| \]
\end{Iteration Error}

While it is often impossible to calculate \(\epsilon_n\) it is very easy to calculate \(\delta_n\) from the generated approximations. This estimate is best used when we know that the convergence is rapid, as in these cases \(\delta_n\) is a good approximation of \(\epsilon_n\).

%SUB%
\subsection{Convergence}
\label{SEC_"Convergence"}

\thoremstyle{definition}
\newtheorem{Uniform Convergence}{Definition}[subsection]
\newtheorem{Rate of Convergence}[Uniform Convergence]{Definition}

\theoremstyle{remark}
\newtheorem{Uniform Convergence R1}{Remark}[Uniform Convergence]

\theoremstyle{plain}
\newtheorem{Uniform Convergence Thm}{Theorem}[subsection]
\newtheorem{Quad Convergence of Newton}[Uniform Convergence Thm]{Theorem}

As our methods of approximating functions will typically generate a sequence of values \(x_0, x_1, x_2, \ldots\) then we want to ensure that the approximations are approaching the correct value. We consider here what it means for a sequence to converge to a limit value, and some useful results for later chapters.

%DEF%
\begin{Uniform Convergence}
\label{DEF_"Uniform Convergence"}
A sequence \((x_n \in \R: n \in \N)\) converges to \(x\) uniformly if \[\forall \tau \in \Rpz \exists N \in \N : \epsilon_n := |x - x_n| < \tau \forall n \in [N, \infty) \cap \Z\]
\end{Uniform Convergence}

%RMK%
\begin{Uniform Convergence R1}
\label{RMK_"Uniform Convergence R1"}
We will typically use the notation that \(\lim_{n \to \infty} |x_n - x| = 0\), to denote that \((x_n : n \in \N)\) converges to \(x\).
\end{Uniform Convergence R1}

%THM%
\begin{Uniform Convergence Thm}
\label{THM_"Uniform Convergence Thm"}
\((x_n \in \R : n \in \N)\) converges to \(x\) uniformly if and only if \[\forall \tau \in \Rpz \exists N \in \N : |x_n - x_m| < \tau \forall m, n \in [N, \infty) \cap \Z\]
\end{Uniform Convergence Delta}
\begin{proof}
For \(\implies\):\\
Suppose that \((x_n : n \in \N)\) converges to \(x\) uniformly. Then \(\forall \tau \in \Rpz \exists N \in \N : |x_n - x| < \tau \forall n \in [N, \infty) \cap \Z\).\\
Thus suppose \(N \in \N\) is such that \(|x_n - x| < \frac{\tau}{2} \forall n \in [N, \infty) \cap \Z\).\\
Then if \(n, m \ge N\) we see that \[|x_n - x_m| \le |x_n - x| + |x_m - x| \le \tau\]\\

For \(\Leftarrow\):\\
Omitted for brevity.
\end{proof}

We have shown now what it means for a value to converge to a limit, but not all sequences that approach a limit do so at the same pace. For example if we consider the sequences \(x_n := 2^-n\) and \(y_n := 10^-n\), then it is obvious that the limit of both sequences is \(0\), but \(y_n\) approaches the limit faster. This leads to the following definition of the rate of convergence.

\begin{Rate of Convergence}
If \((x_n \in \R : n \in \N)\) is a sequence that converges to \(x\), then it is said to converge:
\begin{itemize}
\item Linearly if \(\lambda \in \Rp\) and \[\lim_{n\to\infty}\frac{|x_{n+1} - x|}{|x_n - x|} = \lambda\]
\item Quadratically if \(\lambda \in \Rp\) and \[\lim_{n\to\infty}\frac{|x_{n+1} - x|}{|x_n - x|^2} = \lambda\]
\item Order \(\alpha \in \Rpz\) if \(\lambda \in \Rp\) and \[\lim_{n\to\infty}\frac{|x_{n+1} - x|}{|x_n - x|^\alpha} = \lambda\]
\end{itemize}
\end{Rate of Convergence}

The higher the order of convergence of a sequence the faster it approaches it's limit, therefore we are looking for algorithms with high orders of convergence. Many regular series have linear convergence and quadratic convergence is typically very rapid, while orders above quadratic are hard to construct for useful functions.\\

A useful result is that, under the correct circumstances, the Newton-Raphson method can be shown to have quadratic convergence. The following proof assumes that \(\epsilon_n := |x^\ast - x_n|\):

%THM%
\begin{Quad Convergence of Newton}
\label{THM_"Quad Conv Newton"}
Let \(f\) be a twice differentiable function, \(x^\ast\) be a solution to \(f(x) = 0\) and \((x_n : n \in \N)\) be a sequence produced by the Newton-Raphson Method from some initial point \(x_0\). If the following are satisfied, then \((x_n : n \in \N_0)\) converges quadratically to \(x^\ast\):
\begin{description}

\item[\(\textrm{NR}_1\):]
\begin{math}
	f'(x) \neq 0 \forall x \in I := [x^\ast - r, x^\ast + r], \ \mathrm{where}\ r \in \left[\left|x^\ast - x_0\right|, \infty\right)
\end{math}

\item[\(\textrm{NR}_2\):]
\begin{math}
	f''(x) \ \textrm{is continuous}\  \forall x \in I
\end{math}

\item[\(\textrm{NR}_3\):]
\begin{math}
	M\left|\epsilon_0\right| < 1 \ \mathrm{where}\ M := \sup\left\{\left|\frac{f''(x)}{f'(x)}\right| : x \in I\right\}\\
\end{math}
\end{description}
\end{Quad Convergence of Newton}

\begin{proof}
By Taylor's Theorem with Lagrange Remainders we have that
\begin{displaymath}
	0 = f(x^\ast) = f(x_n) + (x^\ast - x_n)f'(x_n) + \frac{1}{2}
		(x^\ast - x_n)^2f''(y_n)
\end{displaymath}
where \(0 < |x^\ast - y_n| < |x^\ast - x_n|\).\\

Then we get the following derivation:
\begin{displaymath}
\begin{align*}
	&f(x_n) + (x^\ast - x_n)f'(x_n) = 
		-\frac{1}{2}(x^\ast - x_n)^2f''(y_n)\\
	\implies &(\frac{f(x_n)}{f'(x_n)} - x_n) + x^\ast =
		-\frac{1}{2}\frac{f''(y_n)}{f'(x_n)}(x^\ast - x_n)^2
		&\textrm{as} \ \textrm{NR}_3 \implies f'(x_n) \neq 0\\
	\implies &x^\ast - x_{n+1} = 
		-\frac{1}{2}\frac{f''(y_n)}{f'(x_n)}(x^\ast - x_n)^2\\
	\implies &\epsilon_{n+1} =
		\frac{1}{2}\left|\frac{f''(y_n)}{f'(x_n)}\right|\epsilon_n^2
		&\textrm{by taking absolute values}
\end{align*}
\end{displaymath}
As \(\textrm{NR}_2\) holds then \(M\) exists and is positive, and therefore we have:
\[\epsilon_n \le M\epsilon_{n-1}^2 \le M^{2^n - 1}\epsilon_0^{2^n}\]

We now aim to show that we have convergence, i.e. \(\lim_{n \to \infty} x_n = x^\ast\); to do this it suffices to show that \(\lim_{n\to\infty}\epsilon_n = 0\).\\

Consider the sequence \((z_n := M^{2^n - 1}\epsilon_0^{2^n} : n \in \N_0)\). We know that \(0 \le \epsilon_n \le z_n \forall n \in \N_0\), so it then follows that if \(\lim_{n \to \infty}z_n = 0\), then \(\lim_{n \to \infty}\epsilon_n = 0\) by the Squeeze Theorem \ref{#BIBREF#}.\\

Now as \(M\epsilon_0 < 1\) by \(\textrm{NR}_3\), then we see that:

\begin{displaymath}
\begin{align*}
\lim_{n\to\infty}z_n 
	&= \lim_{n\to\infty}(M\epsilon_0)^{2^n - 1}\epsilon_0\\ 
	&= \epsilon_0\lim_{n\to\infty}(M\epsilon_0)^{2^n - 1}\\
	&= \epsilon_0\cdot0
		&\textrm{because } \lim_{n\to\infty}r^{m_n} = 0 \textrm{where }
			|r| < 1, m_n \ge n \forall n \in \N\\
	&= 0
\end{align*}
\end{displaymath}

Now to show that this sequence converges quadratically we see that \(\epsilon_{n+1} = \frac{1}{2}\left|\frac{f''(y_n)}{f'(x_n)}\right|\epsilon_n^2\), and therefore \(\frac{\epsilon_{n+1}}{\epsilon_n^2} = \frac{1}{2}\left|\frac{f''(y_n)}{f'(x_n)}\right|\).\\

Because \(|x^\ast - y_n| < |x^\ast - x_n|\) and \(\lim_{n\to\infty}x_n = x^\ast\), then it follows that \(\lim_{n\to\infty}y_n = x^\ast\). Therefore we see that
\[\lim_{n\to\infty}\frac{\epsilon_{n+1}}{\epsilon_n} = \frac{1}{2}\left|\frac{f''(x^\ast)}{f'(x^\ast)}\right| \in \Rp\]

Hence as the above limit exists and is positive then the sequence is quadratically convergent.
\end{proof}

%SUB%
\subsection{Efficiency Metrics}
\label{SUB_"Efficiency Metrics"}

Now that we have discussed how to measure the accuracy of our results by their errors, we wish to consider the efficiency method. There is typically a trade-off between accuracy and efficiency in that to gain a more accurate result, more calculations are required thus taking up more resources. In general though we will be using efficiency metrics to compare how efficient two different algorithms are at getting the same result.\\

There are two main ways in which we will measure the efficiency of an algorithm. The first of these methods is the theoretical complexity of the algorithm, which represents the number of steps/operations an algorithm needs to achieve it's goal. The complexity of an algorithm is denoted by the big O notation, which represents the order of the complexity, i.e. the highest order term in the number of operations required.\\

Typically the execution of an algorithm depends on the size of the input and so if we consider that an input has size \(n\) we can discuss different complexities. The first consideration is that if one algorithm takes \(2n\) operations while another takes \(20n\) operations, then both algorithms have a complexity of \(\bigO(n)\). \\

A complexity of \(\bigO(n)\) is not a bad complexity for an algorithm as the number of operations needed rises linearly with the size of the input. Complexities of \(\bigO(n^2)\), \(\bigO(2^n)\) and \(\bigO(n!)\) are all poor complexities for an algorithm with the latter two becoming infeasible for larger \(n\). On the other hand complexities better than \(\bigO(n)\) include \(\bigO(\log(n))\) and \(\bigO(1)\), the latter of these is particularly significant as it means that the algorithm takes the same number of steps regardless of the size of the input.\\

The second method of assessing efficiency is timing of functions during execution. This method directly observes how long it takes a computer to perform the calculations for a given algorithm and can be used to empirically test the speed of two algorithms. One remark is that due to the speed of modern computers it is infeasible to time the execution of a single function, and one typically times the same algorithm with the same input being calculated multiple times to get accurate and measurable timings.
